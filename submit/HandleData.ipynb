{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb71590c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "from PIL import Image\n",
    "import io\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import clip\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7810e940",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "clip_model, preprocess = clip.load(\"ViT-B/32\", device=device, jit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a991748d",
   "metadata": {},
   "source": [
    "## 加载yolo数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9827883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# JSON文件路径\n",
    "json_file_path = \"/data/lab/STA-AS2/big_yolo_train.json\"\n",
    "\n",
    "# 打开并读取JSON文件\n",
    "with open(json_file_path, 'r') as json_file:\n",
    "    xuanzi = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa29b08",
   "metadata": {},
   "source": [
    "## 分块跑代码保存数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582ea31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = []\n",
    "all_captions = []\n",
    "for q in range(20,38):\n",
    "    path = f\"/data/lab/STA-AS2/Orogindata/train-{q}.parquet\"\n",
    "    table = pq.read_table(path)\n",
    "    df = table.to_pandas()\n",
    "    for m in range(3):\n",
    "        for i in tqdm(range(1000*m,1000*(m+1)), desc=\"Processing images\"):\n",
    "            if(i==2981):\n",
    "                break\n",
    "            row = df.loc[i]\n",
    "            image_data_dict = row[\"image\"] \n",
    "            image_data = image_data_dict.get(\"bytes\", None)  # 获取二进制图像数据\n",
    "            image = Image.open(io.BytesIO(image_data))\n",
    "            image = preprocess(image).unsqueeze(0).to(device)\n",
    "            with torch.no_grad():\n",
    "                prefix = clip_model.encode_image(image).to(device)\n",
    "\n",
    "            id00 = row[\"sentids\"][0]\n",
    "            imageid = row[\"cocoid\"]\n",
    "            caption = row [\"sentences_raw\"][0]\n",
    "            a = {}\n",
    "            a[\"imageid\"]=imageid\n",
    "            a[\"id\"] =id00\n",
    "            a[\"caption\"]=caption\n",
    "            a[\"clip_embedding\"] = i\n",
    "\n",
    "            more = xuanzi[str(imageid)]\n",
    "            text = clip.tokenize(more).to(device)\n",
    "            text_features = clip_model.encode_text(text)\n",
    "\n",
    "            prefix_more = torch.cat((prefix,text_features),dim=1)\n",
    "            all_embeddings.append(prefix_more)\n",
    "            all_captions.append(a)\n",
    "\n",
    "\n",
    "        torch.save(all_embeddings, f'/data/lab/STA-AS2/Formerge/{q}-{m}.pt')\n",
    "        with open(f'/data/lab/STA-AS2/Formerge/{q}-{m}.pkl', 'wb') as pkl_file:\n",
    "            pickle.dump(all_captions, pkl_file)\n",
    "        all_embeddings.clear()\n",
    "        all_captions.clear()\n",
    "    print(f'{q}-Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f340f07",
   "metadata": {},
   "source": [
    "## 合并数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8425c141",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "总进度: 100%|██████████| 3/3 [00:00<00:00,  7.92it/s]\n"
     ]
    }
   ],
   "source": [
    "merge_tensor = []\n",
    "merge_dict = []\n",
    "for i in tqdm(range(3), desc=\"总进度\"):\n",
    "    for o in range(3):\n",
    "        pklpath = f\"/data/lab/STA-AS2/littlemerge/{i}-{o}.pkl\"\n",
    "        ptpath = f\"/data/lab/STA-AS2/littlemerge/{i}-{o}.pt\"\n",
    "        \n",
    "        with open(pklpath, 'rb') as pkl_file:\n",
    "            loaded_data = pickle.load(pkl_file)\n",
    "        merge_dict.extend(loaded_data)\n",
    "        \n",
    "        tmp = torch.load(ptpath)\n",
    "        merge_tensor.extend(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49ba497",
   "metadata": {},
   "source": [
    "## 输出训练数据格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fc97714",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = \"/data/lab/STA-AS2/oscar_split_ViT-B_train4.pkl\"\n",
    "with open(out_path, 'wb') as f:\n",
    "    pickle.dump({\"clip_embedding\": torch.cat(merge_tensor, dim=0), \"captions\": merge_dict}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c726f422",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
